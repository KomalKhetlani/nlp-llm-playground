{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c2ce3ad07d8f44c9912d8e9cdb60afbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3fe9d160a9074918b19f1ecf03454cb3",
              "IPY_MODEL_6ee059eefd08432fbe3c487adecd7a77",
              "IPY_MODEL_284691452d8e4884ac2fb4c06164b3f6"
            ],
            "layout": "IPY_MODEL_80bc69d04cdb4cd3ad05832e26745c1f"
          }
        },
        "3fe9d160a9074918b19f1ecf03454cb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5b18b45b320473296284e2912072036",
            "placeholder": "​",
            "style": "IPY_MODEL_c899a278f1c44fe6a478719b1235b52d",
            "value": "Map: 100%"
          }
        },
        "6ee059eefd08432fbe3c487adecd7a77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8456fad0ac2043c68ccf74eb36044beb",
            "max": 25000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ec0794665004486ab8341f2f7fb41a46",
            "value": 25000
          }
        },
        "284691452d8e4884ac2fb4c06164b3f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a07b9661878b4613ba4f36642507d146",
            "placeholder": "​",
            "style": "IPY_MODEL_e6b2e088104c4bdd90b9903d48ad328a",
            "value": " 25000/25000 [00:22&lt;00:00, 1146.23 examples/s]"
          }
        },
        "80bc69d04cdb4cd3ad05832e26745c1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5b18b45b320473296284e2912072036": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c899a278f1c44fe6a478719b1235b52d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8456fad0ac2043c68ccf74eb36044beb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec0794665004486ab8341f2f7fb41a46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a07b9661878b4613ba4f36642507d146": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6b2e088104c4bdd90b9903d48ad328a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!jupyter nbextension disable --py widgetsnbextension"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHFTyIKO0304",
        "outputId": "513b1c17-b529-48ae-df1f-85daba015baf"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Disabling notebook extension jupyter-js-widgets/extension...\n",
            "      - Validating: \u001b[32mOK\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IMDB Sentiment Classification with BERT Fine-Tuning\n",
        "\n",
        "In this experiment, we explore how fine-tuning improves the performance of a pre-trained transformer model (BERT) on a downstream sentiment analysis task.\n",
        "\n",
        "We use the IMDB movie reviews dataset, which consists of 50,000 labeled reviews (positive or negative). The goal is to classify the sentiment of each review correctly.\n",
        "\n",
        "We start by evaluating the pre-trained BERT model (bert-base-uncased) on the test set without fine-tuning — this acts as our baseline performance. Then, we fine-tune the model on the IMDB training data and evaluate it again to measure the improvement.\n",
        "\n",
        "Experiment Steps\n",
        "\n",
        "1. Load and preprocess the IMDB dataset\n",
        "2. Tokenize text using BERT tokenizer\n",
        "3. Evaluate baseline i.e. pretrained model, no finetuning\n",
        "4. Fine-tune BERT on IMDB training data\n",
        "5. Evaliuate and comapre model perdormance before and after finetuning"
      ],
      "metadata": {
        "id": "QeRC8SBTkpym"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "sHzRuLCHjc2p"
      },
      "outputs": [],
      "source": [
        "# Import the Libraries\n",
        "from datasets import load_dataset\n",
        "from collections import Counter\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer\n",
        "from transformers import TrainingArguments\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load IMDB dataset\n",
        "dataset = load_dataset(\"imdb\")\n",
        "train_dataset = dataset[\"train\"]\n",
        "test_dataset = dataset[\"test\"]\n"
      ],
      "metadata": {
        "id": "lsanNomAjeoy"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A little bit of EDA\n",
        "print(train_dataset.column_names)\n",
        "print(train_dataset.features)\n",
        "# Count labels in training dataset\n",
        "train_counts = Counter(train_dataset['label'])\n",
        "print(\"Train set label counts:\", train_counts)\n",
        "\n",
        "# Count labels in test dataset\n",
        "test_counts = Counter(test_dataset['label'])\n",
        "print(\"Test set label counts:\", test_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVKX_vpQliEW",
        "outputId": "f397c866-3e03-4c19-c7b2-a000f2ec2b38"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['text', 'label']\n",
            "{'text': Value('string'), 'label': ClassLabel(names=['neg', 'pos'])}\n",
            "Train set label counts: Counter({0: 12500, 1: 12500})\n",
            "Test set label counts: Counter({0: 12500, 1: 12500})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is equal distribution of positive and negative classes in both train and test set. Let continue with that."
      ],
      "metadata": {
        "id": "_ACnMAPN3pzF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load tokenizer and model\n",
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "B4ssPQmUjf5Q"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_fn(batch):\n",
        "  \"\"\"\n",
        "  Tokenizes each batch of text samples so they can be fed into the BERT model\n",
        "  \"\"\"\n",
        "  return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=256)\n"
      ],
      "metadata": {
        "id": "VKwsVxmdjhdL"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we are applying tokenize_fn to every element of the dataset, passed in batches\n",
        "encoded_train = train_dataset.map(tokenize_fn, batched=True)\n",
        "encoded_test = test_dataset.map(tokenize_fn, batched=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "c2ce3ad07d8f44c9912d8e9cdb60afbf",
            "3fe9d160a9074918b19f1ecf03454cb3",
            "6ee059eefd08432fbe3c487adecd7a77",
            "284691452d8e4884ac2fb4c06164b3f6",
            "80bc69d04cdb4cd3ad05832e26745c1f",
            "a5b18b45b320473296284e2912072036",
            "c899a278f1c44fe6a478719b1235b52d",
            "8456fad0ac2043c68ccf74eb36044beb",
            "ec0794665004486ab8341f2f7fb41a46",
            "a07b9661878b4613ba4f36642507d146",
            "e6b2e088104c4bdd90b9903d48ad328a"
          ]
        },
        "id": "8gjm8rlAjjyO",
        "outputId": "0ff80ee9-55f0-44ac-8e03-91fceb1122e0"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c2ce3ad07d8f44c9912d8e9cdb60afbf"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert tokenized dataset columns to PyTorch tensors so they can be directly fed into the BERT model\n",
        "encoded_train.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "encoded_test.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n"
      ],
      "metadata": {
        "id": "om2Z6M6vjlFN"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained model\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHxzyYqwjmYo",
        "outputId": "f91fad51-90cb-4491-d48f-00ecbfc13c37"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation metric\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = np.argmax(pred.predictions, axis=1)\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    f1 = f1_score(labels, preds)\n",
        "    return {\"accuracy\": acc, \"f1\": f1}\n"
      ],
      "metadata": {
        "id": "sh_JNGDAjnlJ"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate before fine-tuning (zero-shot)\n",
        "trainer = Trainer(model=model, tokenizer=tokenizer)\n",
        "preds = trainer.predict(encoded_test)\n",
        "baseline_metrics = compute_metrics(preds)\n",
        "print(\"Before fine-tuning:\", baseline_metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "6pguLCGmjo6e",
        "outputId": "846320de-81e3-4b03-c5b3-0a049f082961"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3012775205.py:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(model=model, tokenizer=tokenizer)\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before fine-tuning: {'accuracy': 0.5126, 'f1': 0.31224247897499574}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "# Fine-tune i.e Configuring the behaviour of the training\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\", # Directory where model checkpoints and final models will be saved\n",
        "    eval_strategy=\"epoch\", # Run evaluation at the end of each training epoch\n",
        "    save_strategy=\"epoch\", # Save model checkpoints at the end of each epoch\n",
        "    learning_rate=2e-5, # Learning rate for the optimizer\n",
        "    per_device_train_batch_size=8, # Batch size per GPU/CPU for training\n",
        "    per_device_eval_batch_size=8, # Batch size per GPU/CPU for evaluation\n",
        "    num_train_epochs=5,  # Total number of passes through the training dataset\n",
        "    weight_decay=0.01, # L2 regularization to prevent overfitting\n",
        "    logging_dir=\"./logs\",  # Directory where training logs (for TensorBoard) will be saved\n",
        "    logging_steps=100, # Log training metrics every 100 steps\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbaRo65fjqZy",
        "outputId": "5f4d7764-bfd1-4f55-8f12-0347933b04c8"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model, # The pre-trained BERT model to fine-tune\n",
        "    args=training_args, # Training configuration defined in TrainingArguments\n",
        "    train_dataset=encoded_train.shuffle(seed=42),  # Full training dataset, shuffled\n",
        "    eval_dataset=encoded_test, # Full test dataset for evaluation\n",
        "    tokenizer=tokenizer, # The BERT tokenizer used for encoding text inputs\n",
        "    compute_metrics=compute_metrics, # Function to calculate evaluation metrics (e.g., accuracy, F1)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdRWuqJOjr1D",
        "outputId": "c34d1022-87a6-4edc-d223-9de3faa1ef72"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-845962478.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "r_RZCSXbjs7Y",
        "outputId": "d44cc851-9a80-4ad3-fb2b-0d66bf167ce6"
      },
      "execution_count": 44,
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6274' max='15625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 6274/15625 51:47 < 1:17:13, 2.02 it/s, Epoch 2.01/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.234500</td>\n",
              "      <td>0.330994</td>\n",
              "      <td>0.910120</td>\n",
              "      <td>0.913400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.255500</td>\n",
              "      <td>0.310378</td>\n",
              "      <td>0.909760</td>\n",
              "      <td>0.914011</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='15625' max='15625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [15625/15625 2:08:35, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.234500</td>\n",
              "      <td>0.330994</td>\n",
              "      <td>0.910120</td>\n",
              "      <td>0.913400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.255500</td>\n",
              "      <td>0.310378</td>\n",
              "      <td>0.909760</td>\n",
              "      <td>0.914011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.121400</td>\n",
              "      <td>0.414992</td>\n",
              "      <td>0.919640</td>\n",
              "      <td>0.919301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.026000</td>\n",
              "      <td>0.558844</td>\n",
              "      <td>0.919840</td>\n",
              "      <td>0.919213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.022500</td>\n",
              "      <td>0.577345</td>\n",
              "      <td>0.920880</td>\n",
              "      <td>0.921183</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=15625, training_loss=0.13500612687200308, metrics={'train_runtime': 7716.3001, 'train_samples_per_second': 16.199, 'train_steps_per_second': 2.025, 'total_flos': 1.644444096e+16, 'train_loss': 0.13500612687200308, 'epoch': 5.0})"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate after fine-tuning\n",
        "preds_after = trainer.predict(encoded_test)\n",
        "finetuned_metrics = compute_metrics(preds_after)\n",
        "print(\"After fine-tuning:\", finetuned_metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "2N1NRZvejuRW",
        "outputId": "d44f213a-1ad9-4af2-ee8b-bf008ff6cda0"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After fine-tuning: {'accuracy': 0.92088, 'f1': 0.9211826585910106}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9uQeZajAjvYe"
      },
      "execution_count": 45,
      "outputs": []
    }
  ]
}