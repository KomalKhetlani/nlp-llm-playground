{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Sentence Similarity Experiment Using Embeddings**\n",
        "\n",
        "This notebook lets you compare any two sentences and calculates a semantic similarity score, showing how close their meanings are using pre-trained sentence embeddings.\n"
      ],
      "metadata": {
        "id": "DbGgWLfnG5Ve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the sentence-transformers library\n",
        "# - Provides pre-trained models to generate embeddings for sentences, paragraphs, or documents.\n",
        "# - Embeddings are numerical vector representations of text, capturing semantic meaning.\n",
        "\n",
        "!pip install -q sentence-transformers"
      ],
      "metadata": {
        "id": "h06sA0F1B7HF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "C53ZG4HgCIf4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a pre-trained sentence transformer model\n",
        "# 'all-MiniLM-L6-v2' is lightweight, fast, and effective for semantic similarity tasks.\n",
        "embed_model = SentenceTransformer('all-MiniLM-L6-v2')"
      ],
      "metadata": {
        "id": "-y3LGnCICM-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_sentence_similarity(embed_model, sent1, sent2):\n",
        "  \"\"\"\n",
        "    Compute the semantic similarity between two sentences using embeddings.\n",
        "\n",
        "    Args:\n",
        "        embed_model (SentenceTransformer): Pre-trained sentence transformer model.\n",
        "        sent1 (str): First sentence to compare.\n",
        "        sent2 (str): Second sentence to compare.\n",
        "\n",
        "    Returns:\n",
        "        float: Similarity percentage between 0 and 100.\n",
        "\n",
        "    Steps:\n",
        "        1. Encode each sentence into embeddings.\n",
        "        2. Compute cosine similarity between embeddings.\n",
        "        3. Convert the similarity score to a percentage.\n",
        "    \"\"\"\n",
        "  # Step 1: Generate embeddings for both sentences\n",
        "  emb1 = embed_model.encode([sent1])\n",
        "  emb2 = embed_model.encode([sent2])\n",
        "  # Step 2: Compute cosine similarity between embeddings\n",
        "  sim_score = cosine_similarity(emb1, emb2)[0][0]\n",
        "  # Step 3: Convert similarity to percentage\n",
        "  similarity_percentage = sim_score * 100\n",
        "  return similarity_percentage\n"
      ],
      "metadata": {
        "id": "YUjKt3J3DMkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def interpret_similarity_score(sim_percentage):\n",
        "  \"\"\"\n",
        "    Interpret a similarity score as a human-readable message.\n",
        "\n",
        "    Args:\n",
        "        sim_percentage (float): Similarity score in percentage (0-100).\n",
        "\n",
        "    Returns:\n",
        "        str: Message describing how similar the sentences are.\n",
        "\n",
        "    Thresholds:\n",
        "        >95%  : Highly similar\n",
        "        70-95%: Somewhat similar\n",
        "        <70%  : Not similar\n",
        "    \"\"\"\n",
        "  if sim_percentage > 95:\n",
        "    return \"The sentences are highly similar in meaning.\"\n",
        "  elif sim_percentage > 70:\n",
        "    return \"The sentences are somewhat similar.\"\n",
        "  else:\n",
        "    return \"The sentences are not similar.\"\n"
      ],
      "metadata": {
        "id": "GRXboRoHD9my"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Interactive user input\n",
        "# Prompt the user to enter two sentences for comparison\n",
        "sentence1 = input(\"Enter the first sentence: \")\n",
        "sentence2 = input(\"Enter the second sentence: \")\n",
        "\n",
        "# Compute similarity score\n",
        "similarity_score = compare_sentence_similarity(embed_model,sentence1, sentence2)\n",
        "# Interpret the similarity score\n",
        "are_they_similar = interpret_similarity_score(similarity_score)\n",
        "# Display results\n",
        "print(\"Result = \")\n",
        "print(are_they_similar)\n",
        "print(\"Similarity Score = {:.2f}%\".format(similarity_score))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iON5yWNLEWMr",
        "outputId": "5302e042-5ce7-4e18-a278-3d171688a6e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the first sentence: My dog is happy.\n",
            "Enter the second sentence: My cat is sad.\n",
            "Result = \n",
            "The sentences are not similar.\n",
            "Similarity Score = 55.59%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UoXHB9H_Ehpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M50b-ELAEj81"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}